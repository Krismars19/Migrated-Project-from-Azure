{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Multiple linear regression"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Import the relevant libraries"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# For these lessons we will need NumPy, pandas, matplotlib and seaborn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# and of course the actual regression (machine learning) module\nfrom sklearn.linear_model import LinearRegression",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load the data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the data from a .csv in the same folder\ndata = pd.read_csv('1.02. Multiple linear regression.csv')\n\n# Let's explore the top 5 rows of the df\ndata.head()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAT</th>\n      <th>Rand 1,2,3</th>\n      <th>GPA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1714</td>\n      <td>1</td>\n      <td>2.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1664</td>\n      <td>3</td>\n      <td>2.52</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1760</td>\n      <td>3</td>\n      <td>2.54</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1685</td>\n      <td>3</td>\n      <td>2.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1693</td>\n      <td>2</td>\n      <td>2.83</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    SAT  Rand 1,2,3   GPA\n0  1714           1  2.40\n1  1664           3  2.52\n2  1760           3  2.54\n3  1685           3  2.74\n4  1693           2  2.83"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This method gives us very nice descriptive statistics. We don't need this for now, but will later on!\ndata.describe()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAT</th>\n      <th>Rand 1,2,3</th>\n      <th>GPA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>84.000000</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1845.273810</td>\n      <td>2.059524</td>\n      <td>3.330238</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>104.530661</td>\n      <td>0.855192</td>\n      <td>0.271617</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1634.000000</td>\n      <td>1.000000</td>\n      <td>2.400000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1772.000000</td>\n      <td>1.000000</td>\n      <td>3.190000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1846.000000</td>\n      <td>2.000000</td>\n      <td>3.380000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1934.000000</td>\n      <td>3.000000</td>\n      <td>3.502500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2050.000000</td>\n      <td>3.000000</td>\n      <td>3.810000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "               SAT  Rand 1,2,3        GPA\ncount    84.000000   84.000000  84.000000\nmean   1845.273810    2.059524   3.330238\nstd     104.530661    0.855192   0.271617\nmin    1634.000000    1.000000   2.400000\n25%    1772.000000    1.000000   3.190000\n50%    1846.000000    2.000000   3.380000\n75%    1934.000000    3.000000   3.502500\nmax    2050.000000    3.000000   3.810000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create the multiple linear regression"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Declare the dependent and independent variables"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# There are two independent variables: 'SAT' and 'Rand 1,2,3'\nx = data[['SAT','Rand 1,2,3']]\n\n# and a single depended variable: 'GPA'\ny = data['GPA']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Regression itself"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# We start by creating a linear regression object\nreg = LinearRegression()\n\n# The whole learning process boils down to fitting the regression\nreg.fit(x,y)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Getting the coefficients of the regression\nreg.coef_\n# Note that the output is an array",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "array([ 0.00165354, -0.00826982])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Getting the intercept of the regression\nreg.intercept_\n# Note that the result is a float as we usually expect a single value",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "0.29603261264909486"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Calculating the R-squared"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get the R-squared of the regression\nreg.score(x,y)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "0.4066811952814285"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Formula for Adjusted R^2\n\n$R^2_{adj.} = 1 - (1-R^2)*\\frac{n-1}{n-p-1}$"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get the shape of x, to facilitate the creation of the Adjusted R^2 metric\nx.shape",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "(84, 2)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# If we want to find the Adjusted R-squared we can do so by knowing the r2, the # observations, the # features\nr2 = reg.score(x,y)\n# Number of observations is the shape along axis 0\nn = x.shape[0]\n# Number of features (predictors, p) is the shape along axis 1\np = x.shape[1]\n\n# We find the Adjusted R-squared using the formula\nadjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\nadjusted_r2",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "0.39203134825134023"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Feature selection\nFull documentation: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import the feature selection module from sklearn\n# This module allows us to select the most appopriate features for our regression\n# There exist many different approaches to feature selection, however, we will use one of the simplest\nfrom sklearn.feature_selection import f_regression",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# We will look into: f_regression\n# f_regression finds the F-statistics for the *simple* regressions created with each of the independent variables\n# In our case, this would mean running a simple linear regression on GPA where SAT is the independent variable\n# and a simple linear regression on GPA where Rand 1,2,3 is the indepdent variable\n# The limitation of this approach is that it does not take into account the mutual effect of the two features\nf_regression(x,y)\n\n# There are two output arrays\n# The first one contains the F-statistics for each of the regressions\n# The second one contains the p-values of these F-statistics",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "(array([56.04804786,  0.17558437]), array([7.19951844e-11, 6.76291372e-01]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Since we are more interested in the latter (p-values), we can just take the second array\np_values = f_regression(x,y)[1]\np_values",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "array([7.19951844e-11, 6.76291372e-01])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# To be able to quickly evaluate them, we can round the result to 3 digits after the dot\np_values.round(3)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "array([0.   , 0.676])"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}