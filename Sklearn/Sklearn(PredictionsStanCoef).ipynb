{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Making Predictions with the Standardized Coefficients"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Import the relevant libraries"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# For these lessons we will need NumPy, pandas, matplotlib and seaborn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# and of course the actual regression (machine learning) module\nfrom sklearn.linear_model import LinearRegression",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load the data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the data from a .csv in the same folder\ndata = pd.read_csv('1.02. Multiple linear regression.csv')\n\n# Let's explore the top 5 rows of the df\ndata.head()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAT</th>\n      <th>Rand 1,2,3</th>\n      <th>GPA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1714</td>\n      <td>1</td>\n      <td>2.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1664</td>\n      <td>3</td>\n      <td>2.52</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1760</td>\n      <td>3</td>\n      <td>2.54</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1685</td>\n      <td>3</td>\n      <td>2.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1693</td>\n      <td>2</td>\n      <td>2.83</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    SAT  Rand 1,2,3   GPA\n0  1714           1  2.40\n1  1664           3  2.52\n2  1760           3  2.54\n3  1685           3  2.74\n4  1693           2  2.83"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.describe()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAT</th>\n      <th>Rand 1,2,3</th>\n      <th>GPA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>84.000000</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1845.273810</td>\n      <td>2.059524</td>\n      <td>3.330238</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>104.530661</td>\n      <td>0.855192</td>\n      <td>0.271617</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1634.000000</td>\n      <td>1.000000</td>\n      <td>2.400000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1772.000000</td>\n      <td>1.000000</td>\n      <td>3.190000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1846.000000</td>\n      <td>2.000000</td>\n      <td>3.380000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1934.000000</td>\n      <td>3.000000</td>\n      <td>3.502500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2050.000000</td>\n      <td>3.000000</td>\n      <td>3.810000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "               SAT  Rand 1,2,3        GPA\ncount    84.000000   84.000000  84.000000\nmean   1845.273810    2.059524   3.330238\nstd     104.530661    0.855192   0.271617\nmin    1634.000000    1.000000   2.400000\n25%    1772.000000    1.000000   3.190000\n50%    1846.000000    2.000000   3.380000\n75%    1934.000000    3.000000   3.502500\nmax    2050.000000    3.000000   3.810000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create the multiple linear regression"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Declare the dependent and independent variables"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# There are two independent variables: 'SAT' and 'Rand 1,2,3'\nx = data[['SAT','Rand 1,2,3']]\n\n# and a single dependent variable: 'GPA'\ny = data['GPA']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Standardization"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import the preprocessing module\n# StandardScaler is one of the easiest and 'cleanest' ways to preprocess your data\nfrom sklearn.preprocessing import StandardScaler",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create an instance of the StandardScaler class\nscaler = StandardScaler()",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Fit the input data (x)\n# Essentially we are calculating the mean and standard deviation feature-wise \n# (the mean of 'SAT' and the standard deviation of 'SAT', \n# as well as the mean of 'Rand 1,2,3' and the standard deviation of 'Rand 1,2,3')\nscaler.fit(x)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "StandardScaler(copy=True, with_mean=True, with_std=True)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# The actual scaling of the data is done through the method 'transform()'\n# Let's store it in a new variable, named appropriately\nx_scaled = scaler.transform(x)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# The result is an ndarray\nx_scaled",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "array([[-1.26338288, -1.24637147],\n       [-1.74458431,  1.10632974],\n       [-0.82067757,  1.10632974],\n       [-1.54247971,  1.10632974],\n       [-1.46548748, -0.07002087],\n       [-1.68684014, -1.24637147],\n       [-0.78218146, -0.07002087],\n       [-0.78218146, -1.24637147],\n       [-0.51270866, -0.07002087],\n       [ 0.04548499,  1.10632974],\n       [-1.06127829,  1.10632974],\n       [-0.67631715, -0.07002087],\n       [-1.06127829, -1.24637147],\n       [-1.28263094,  1.10632974],\n       [-0.6955652 , -0.07002087],\n       [ 0.25721362, -0.07002087],\n       [-0.86879772,  1.10632974],\n       [-1.64834403, -0.07002087],\n       [-0.03150724,  1.10632974],\n       [-0.57045283,  1.10632974],\n       [-0.81105355,  1.10632974],\n       [-1.18639066,  1.10632974],\n       [-1.75420834,  1.10632974],\n       [-1.52323165, -1.24637147],\n       [ 1.23886453, -1.24637147],\n       [-0.18549169, -1.24637147],\n       [-0.5608288 , -1.24637147],\n       [-0.23361183,  1.10632974],\n       [ 1.68156984, -1.24637147],\n       [-0.4934606 , -0.07002087],\n       [-0.73406132, -1.24637147],\n       [ 0.85390339, -1.24637147],\n       [-0.67631715, -1.24637147],\n       [ 0.09360513,  1.10632974],\n       [ 0.33420585, -0.07002087],\n       [ 0.03586096, -0.07002087],\n       [-0.35872421,  1.10632974],\n       [ 1.04638396,  1.10632974],\n       [-0.65706909,  1.10632974],\n       [-0.13737155, -0.07002087],\n       [ 0.18984542,  1.10632974],\n       [ 0.04548499, -1.24637147],\n       [ 1.1618723 ,  1.10632974],\n       [-1.37887123, -1.24637147],\n       [ 1.39284898, -1.24637147],\n       [ 0.76728713, -0.07002087],\n       [-0.20473975, -0.07002087],\n       [ 1.06563201, -1.24637147],\n       [ 0.11285319, -1.24637147],\n       [ 1.28698467,  1.10632974],\n       [-0.41646838,  1.10632974],\n       [ 0.09360513, -1.24637147],\n       [ 0.59405462, -0.07002087],\n       [-2.03330517, -0.07002087],\n       [ 0.32458182, -1.24637147],\n       [ 0.40157405, -1.24637147],\n       [-1.10939843, -0.07002087],\n       [ 1.03675993, -1.24637147],\n       [-0.61857297, -0.07002087],\n       [ 0.44007016, -0.07002087],\n       [ 1.14262424, -1.24637147],\n       [-0.35872421,  1.10632974],\n       [ 0.45931822,  1.10632974],\n       [ 1.88367444,  1.10632974],\n       [ 0.45931822, -1.24637147],\n       [-0.12774752, -0.07002087],\n       [ 0.04548499,  1.10632974],\n       [ 0.85390339, -0.07002087],\n       [ 0.15134931, -0.07002087],\n       [ 0.8250313 ,  1.10632974],\n       [ 0.84427936,  1.10632974],\n       [-0.64744506, -1.24637147],\n       [ 1.24848856, -1.24637147],\n       [ 0.85390339,  1.10632974],\n       [ 1.69119387,  1.10632974],\n       [ 1.6334497 ,  1.10632974],\n       [ 1.46021718, -1.24637147],\n       [ 1.68156984, -0.07002087],\n       [-0.02188321,  1.10632974],\n       [ 0.87315144,  1.10632974],\n       [-0.33947615, -1.24637147],\n       [ 1.3639769 ,  1.10632974],\n       [ 1.12337618, -1.24637147],\n       [ 1.97029069, -0.07002087]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Regression with scaled features"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creating a regression works in the exact same way\nreg = LinearRegression()\n\n# We just need to specify that our inputs are the 'scaled inputs'\nreg.fit(x_scaled,y)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Let's see the coefficients\nreg.coef_",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "array([ 0.17181389, -0.00703007])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# And the intercept\nreg.intercept_",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "3.330238095238095"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Creating a summary table"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# As usual we can try to arrange the information in a summary table\n# Let's create a new data frame with the names of the features\nreg_summary = pd.DataFrame([['Bias'],['SAT'],['Rand 1,2,3']], columns=['Features'])\n\n# Then we create and fill a second column, called 'Weights' with the coefficients of the regression\n# Since the standardized coefficients are called 'weights' in ML, this is a much better word choice for our case\n# Note that even non-standardized coeff. are called 'weights' \n# but more often than not, when doing ML we perform some sort of scaling\nreg_summary['Weights'] = reg.intercept_, reg.coef_[0], reg.coef_[1]",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now we have a pretty clean summary, which can help us make an informed decision about the importance of each feature\nreg_summary",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Features</th>\n      <th>Weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bias</td>\n      <td>3.330238</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SAT</td>\n      <td>0.171814</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rand 1,2,3</td>\n      <td>-0.007030</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "     Features   Weights\n0        Bias  3.330238\n1         SAT  0.171814\n2  Rand 1,2,3 -0.007030"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Making predictions with the standardized coefficients (weights)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# For simplicity, let's crete a new dataframe with 2 *new* observations\nnew_data = pd.DataFrame(data=[[1700,2],[1800,1]],columns=['SAT','Rand 1,2,3'])\nnew_data",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAT</th>\n      <th>Rand 1,2,3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1700</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1800</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    SAT  Rand 1,2,3\n0  1700           2\n1  1800           1"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# We can make a prediction for a whole dataframe (not a single value)\n# Note that the output is very strange (different from mine)\nreg.predict(new_data)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "array([295.39979563, 312.58821497])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Our model is expecting SCALED features (features of different magnitude)\n# In fact we must transform the 'new data' in the same way as we transformed the inputs we train the model on\n# Luckily for us, this information is contained in the 'scaler' object\n# We simply transform the 'new data' using the relevant method\nnew_data_scaled = scaler.transform(new_data)\n\n# Let's check the result\nnew_data_scaled",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "array([[-1.39811928, -0.07002087],\n       [-0.43571643, -1.24637147]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Finally we make a prediction using the scaled new data\nreg.predict(new_data_scaled)\n# The output is much more appropriate, isn't it?",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "array([3.09051403, 3.26413803])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## What if we removed the 'Random 1,2,3' variable?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Theory suggests that features with very small weights could be removed and the results should be identical\n# Moreover, we proved in 2-3 different ways that 'Rand 1,2,3' is an irrelevant feature\n# Let's create a simple linear regression (simple, because there is a single feature) without 'Rand 1,2,3'\nreg_simple = LinearRegression()\n\n# Once more, we must reshape the inputs into a matrix, otherwise we will get a compatibility error \n# Note that instead of standardizing again, I'll simply take only the first column of x\nx_simple_matrix = x_scaled[:,0].reshape(-1,1)\n\n# Finally, we fit the regression\nreg_simple.fit(x_simple_matrix,y)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# In a similar manner to the cell before, we can predict only the first column of the scaled 'new data'\n# Note that we also reshape it to be exactly the same as x\nreg_simple.predict(new_data_scaled[:,0].reshape(-1,1))",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "array([3.08970998, 3.25527879])"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}